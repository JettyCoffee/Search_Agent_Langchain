#!/usr/bin/env python3
"""
Wikipedia APIè¿æ¥æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•Wikipedia APIæ˜¯å¦èƒ½æ­£å¸¸è¿æ¥å’Œè·å–æ•°æ®
"""

import requests
import json
import sys
from urllib.parse import quote


class WikipediaAPITester:
    def __init__(self):
        self.base_url = "https://zh.wikipedia.org/w/api.php"
        self.session = requests.Session()
        # è®¾ç½®User-Agentä»¥é¿å…è¢«å°ç¦
        self.session.headers.update({
            'User-Agent': 'Wikipedia API Tester/1.0 (https://example.com/contact) requests/2.28.1'
        })

    def test_basic_connection(self):
        """æµ‹è¯•åŸºæœ¬è¿æ¥"""
        print("ğŸ” æµ‹è¯•åŸºæœ¬è¿æ¥...")
        try:
            params = {
                'action': 'query',
                'format': 'json',
                'meta': 'siteinfo',
                'siprop': 'general'
            }
            response = self.session.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if 'query' in data and 'general' in data['query']:
                site_name = data['query']['general'].get('sitename', 'Unknown')
                print(f"âœ… è¿æ¥æˆåŠŸï¼ç«™ç‚¹åç§°: {site_name}")
                return True
            else:
                print("âŒ è¿æ¥å¤±è´¥ï¼šå“åº”æ ¼å¼ä¸æ­£ç¡®")
                return False
                
        except requests.exceptions.ConnectionError:
            print("âŒ è¿æ¥å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ°WikipediaæœåŠ¡å™¨")
            return False
        except requests.exceptions.Timeout:
            print("âŒ è¿æ¥å¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶")
            return False
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¿æ¥å¤±è´¥ï¼š{e}")
            return False
        except json.JSONDecodeError:
            print("âŒ è¿æ¥å¤±è´¥ï¼šå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            return False

    def test_search_functionality(self):
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
        try:
            # æµ‹è¯•æœç´¢"äººå·¥æ™ºèƒ½"
            search_query = "äººå·¥æ™ºèƒ½"
            params = {
                'action': 'query',
                'format': 'json',
                'list': 'search',
                'srsearch': search_query,
                'srlimit': 5
            }
            
            response = self.session.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if 'query' in data and 'search' in data['query']:
                results = data['query']['search']
                print(f"âœ… æœç´¢æˆåŠŸï¼æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
                
                for i, result in enumerate(results[:3], 1):
                    title = result.get('title', 'Unknown')
                    snippet = result.get('snippet', '').replace('<span class="searchmatch">', '').replace('</span>', '')
                    print(f"   {i}. {title}")
                    if snippet:
                        print(f"      æ‘˜è¦: {snippet[:100]}...")
                return True
            else:
                print("âŒ æœç´¢å¤±è´¥ï¼šå“åº”æ ¼å¼ä¸æ­£ç¡®")
                return False
                
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥ï¼š{e}")
            return False

    def test_page_content(self):
        """æµ‹è¯•é¡µé¢å†…å®¹è·å–"""
        print("\nğŸ” æµ‹è¯•é¡µé¢å†…å®¹è·å–...")
        try:
            # è·å–"åŒ—äº¬"é¡µé¢çš„å†…å®¹æ‘˜è¦
            page_title = "åŒ—äº¬"
            params = {
                'action': 'query',
                'format': 'json',
                'titles': page_title,
                'prop': 'extracts',
                'exintro': True,
                'explaintext': True,
                'exsectionformat': 'plain'
            }
            
            response = self.session.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if 'query' in data and 'pages' in data['query']:
                pages = data['query']['pages']
                for page_id, page_data in pages.items():
                    if page_id != '-1':  # -1è¡¨ç¤ºé¡µé¢ä¸å­˜åœ¨
                        title = page_data.get('title', 'Unknown')
                        extract = page_data.get('extract', '')
                        print(f"âœ… é¡µé¢å†…å®¹è·å–æˆåŠŸï¼é¡µé¢: {title}")
                        if extract:
                            print(f"   æ‘˜è¦: {extract[:200]}...")
                        return True
                
                print("âŒ é¡µé¢å†…å®¹è·å–å¤±è´¥ï¼šé¡µé¢ä¸å­˜åœ¨")
                return False
            else:
                print("âŒ é¡µé¢å†…å®¹è·å–å¤±è´¥ï¼šå“åº”æ ¼å¼ä¸æ­£ç¡®")
                return False
                
        except Exception as e:
            print(f"âŒ é¡µé¢å†…å®¹è·å–å¤±è´¥ï¼š{e}")
            return False

    def test_api_limits(self):
        """æµ‹è¯•APIé™åˆ¶"""
        print("\nğŸ” æµ‹è¯•APIé™åˆ¶...")
        try:
            params = {
                'action': 'query',
                'format': 'json',
                'meta': 'userinfo'
            }
            
            response = self.session.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            if 'query' in data and 'userinfo' in data['query']:
                userinfo = data['query']['userinfo']
                user_groups = userinfo.get('groups', [])
                rate_limits = userinfo.get('ratelimits', {})
                
                print("âœ… APIé™åˆ¶ä¿¡æ¯è·å–æˆåŠŸï¼")
                print(f"   ç”¨æˆ·ç»„: {', '.join(user_groups)}")
                if rate_limits:
                    print(f"   é€Ÿç‡é™åˆ¶: {rate_limits}")
                else:
                    print("   é€Ÿç‡é™åˆ¶: æ ‡å‡†é™åˆ¶ï¼ˆåŒ¿åç”¨æˆ·ï¼‰")
                return True
            else:
                print("âŒ APIé™åˆ¶ä¿¡æ¯è·å–å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ APIé™åˆ¶ä¿¡æ¯è·å–å¤±è´¥ï¼š{e}")
            return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹Wikipedia APIè¿æ¥æµ‹è¯•\n")
        print("=" * 50)
        
        tests = [
            ("åŸºæœ¬è¿æ¥æµ‹è¯•", self.test_basic_connection),
            ("æœç´¢åŠŸèƒ½æµ‹è¯•", self.test_search_functionality),
            ("é¡µé¢å†…å®¹è·å–æµ‹è¯•", self.test_page_content),
            ("APIé™åˆ¶æµ‹è¯•", self.test_api_limits)
        ]
        
        results = []
        for test_name, test_func in tests:
            try:
                result = test_func()
                results.append((test_name, result))
            except Exception as e:
                print(f"âŒ {test_name} æ‰§è¡Œå¼‚å¸¸: {e}")
                results.append((test_name, False))
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
        
        passed = 0
        for test_name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"   {test_name}: {status}")
            if result:
                passed += 1
        
        print(f"\næ€»è®¡: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
        
        if passed == len(results):
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Wikipedia APIè¿æ¥æ­£å¸¸")
            return True
        else:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIçŠ¶æ€")
            return False


def main():
    """ä¸»å‡½æ•°"""
    tester = WikipediaAPITester()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
